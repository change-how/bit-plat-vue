# test_csv_support.py - CSVæ”¯æŒåŠŸèƒ½æµ‹è¯•è„šæœ¬

import pandas as pd
from pathlib import Path

def create_test_csv_files():
    """
    åˆ›å»º4ç§ä¸åŒå¸ƒå±€çš„æµ‹è¯•CSVæ–‡ä»¶ï¼Œç”¨äºéªŒè¯CSVå¤„ç†åŠŸèƒ½
    """
    test_dir = Path("./test_csv_files")
    test_dir.mkdir(exist_ok=True)
    
    print("æ­£åœ¨åˆ›å»ºCSVæµ‹è¯•æ–‡ä»¶...")
    
    # 1. æ ‡å‡†è¡¨æ ¼å¸ƒå±€ (tabular)
    print("1. åˆ›å»ºæ ‡å‡†è¡¨æ ¼CSV...")
    tabular_data = {
        'ç”¨æˆ·ID': ['USER001', 'USER002', 'USER003'],
        'äº¤æ˜“ID': ['TXN001', 'TXN002', 'TXN003'], 
        'é‡‘é¢': ['1000.50', '2500.00', '750.25'],
        'å¸ç§': ['BTC', 'ETH', 'USDT'],
        'äº¤æ˜“æ—¶é—´': ['2024-01-01 10:30:00', '2024-01-02 14:15:00', '2024-01-03 09:45:00']
    }
    df_tabular = pd.DataFrame(tabular_data)
    df_tabular.to_csv(test_dir / "test_tabular.csv", index=False, encoding='utf-8-sig')
    
    # 2. è¡¨å•å¸ƒå±€ (form_layout)
    print("2. åˆ›å»ºè¡¨å•å¸ƒå±€CSV...")
    form_data = [
        ['ç”¨æˆ·åŸºæœ¬ä¿¡æ¯', '', '', ''],  # æ ‡é¢˜è¡Œ
        ['ç”¨æˆ·ID', 'å§“å', 'æ‰‹æœºå·', 'é‚®ç®±'],  # è¡¨å¤´è¡Œ
        ['USER001', 'å¼ ä¸‰', '13800138000', 'zhangsan@email.com']  # æ•°æ®è¡Œ
    ]
    df_form = pd.DataFrame(form_data)
    df_form.to_csv(test_dir / "test_form.csv", index=False, header=False, encoding='utf-8-sig')
    
    # 3. åŠ¨æ€å­è¡¨ (find_subtable_by_header)
    print("3. åˆ›å»ºåŠ¨æ€å­è¡¨CSV...")
    subtable_data = [
        ['è¿™æ˜¯ä¸€äº›è¯´æ˜æ–‡å­—', '', '', ''],
        ['', '', '', ''],  # ç©ºè¡Œ
        ['äº¤æ˜“è®°å½•', '', '', ''],  # å­è¡¨æ ‡é¢˜
        ['ç”¨æˆ·ID', 'èµ„äº§ç±»å‹', 'æ“ä½œç±»å‹', 'æ•°é‡'],  # å­è¡¨è¡¨å¤´
        ['USER001', 'BTC', 'å……å€¼', '0.5'],
        ['USER001', 'ETH', 'æç°', '2.0'],
        ['USER002', 'USDT', 'äº¤æ˜“', '1000.0']
    ]
    df_subtable = pd.DataFrame(subtable_data)
    df_subtable.to_csv(test_dir / "test_subtable.csv", index=False, header=False, encoding='utf-8-sig')
    
    # 4. å¤æ‚ä¸‰ç»´è¡¨ (merged_key_value)
    print("4. åˆ›å»ºå¤æ‚ä¸‰ç»´è¡¨CSV...")
    complex_data = [
        ['è®¾å¤‡åç§°', 'è®¾å¤‡ç±»å‹', 'æœ€åä½¿ç”¨æ—¶é—´', 'å±æ€§åç§°', 'å±æ€§å€¼'],
        ['iPhone 14', 'æ‰‹æœº', '2024-01-01 10:00:00', 'IMEI', '123456789012345'],
        ['', '', '', 'iOSç‰ˆæœ¬', '17.2.1'],
        ['', '', '', 'APPç‰ˆæœ¬', '2.1.0'],
        ['MacBook Pro', 'ç”µè„‘', '2024-01-02 15:30:00', 'MACåœ°å€', 'AA:BB:CC:DD:EE:FF'],
        ['', '', '', 'æ“ä½œç³»ç»Ÿ', 'macOS 14.0'],
        ['', '', '', 'æµè§ˆå™¨', 'Safari 17.0']
    ]
    df_complex = pd.DataFrame(complex_data)
    df_complex.to_csv(test_dir / "test_complex.csv", index=False, header=False, encoding='utf-8-sig')
    
    print(f"âœ… æ‰€æœ‰æµ‹è¯•CSVæ–‡ä»¶å·²åˆ›å»ºå®Œæˆï¼Œä¿å­˜åœ¨: {test_dir.absolute()}")
    
    # è¾“å‡ºæ–‡ä»¶ç»“æ„ä¿¡æ¯
    print("\nğŸ“ åˆ›å»ºçš„æ–‡ä»¶ç»“æ„:")
    for csv_file in test_dir.glob("*.csv"):
        print(f"  - {csv_file.name}")
        df = pd.read_csv(csv_file, header=None)
        print(f"    å°ºå¯¸: {df.shape[0]} è¡Œ x {df.shape[1]} åˆ—")
        print(f"    å‰3è¡Œé¢„è§ˆ:")
        for i in range(min(3, len(df))):
            print(f"      {list(df.iloc[i])}")
        print()

def test_csv_processing():
    """
    æµ‹è¯•CSVå¤„ç†åŠŸèƒ½
    """
    try:
        from scripts.data_extract import extract_data_from_sources
        from scripts.utils import load_mapping_config
        
        print("å¼€å§‹æµ‹è¯•CSVå¤„ç†åŠŸèƒ½...")
        
        # åŠ è½½CSVé…ç½®æ¨¡æ¿
        config_path = Path("./config/csv_universal_map.jsonc")
        if not config_path.exists():
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return
            
        mapping_config = load_mapping_config(config_path)
        if not mapping_config:
            print("âŒ æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶")
            return
            
        # æµ‹è¯•æ ‡å‡†è¡¨æ ¼CSV
        test_file = Path("./test_csv_files/test_tabular.csv")
        if test_file.exists():
            print(f"\nğŸ” æµ‹è¯•æ–‡ä»¶: {test_file.name}")
            sources_config = [
                {
                    "source_id": "basic_transactions_raw",
                    "data_layout": "tabular",
                    "header_row": 1
                }
            ]
            
            result = extract_data_from_sources(test_file, sources_config)
            if result:
                print("âœ… CSVå¤„ç†æˆåŠŸ!")
                for source_id, data in result.items():
                    print(f"  æ•°æ®æº '{source_id}': {len(data)} è¡Œæ•°æ®")
                    if hasattr(data, 'columns'):
                        print(f"  åˆ—å: {list(data.columns)}")
            else:
                print("âŒ CSVå¤„ç†å¤±è´¥")
        else:
            print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            
    except ImportError as e:
        print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

if __name__ == "__main__":
    print("=== CSVæ”¯æŒåŠŸèƒ½æµ‹è¯• ===\n")
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    create_test_csv_files()
    
    print("\n" + "="*50 + "\n")
    
    # æµ‹è¯•å¤„ç†åŠŸèƒ½
    test_csv_processing()
    
    print("\n=== æµ‹è¯•å®Œæˆ ===")
    
    print("\nğŸ“– ä½¿ç”¨è¯´æ˜:")
    print("1. ç°åœ¨æ‚¨çš„ç³»ç»Ÿå·²æ”¯æŒCSVæ–‡ä»¶çš„4ç§è¯†åˆ«æ–¹æ³•:")
    print("   - tabular: æ ‡å‡†è¡¨æ ¼å¸ƒå±€")
    print("   - form_layout: è¡¨å•å¸ƒå±€ï¼ˆé”®å€¼å¯¹ï¼‰")
    print("   - find_subtable_by_header: åŠ¨æ€å­è¡¨æŸ¥æ‰¾")
    print("   - merged_key_value: å¤æ‚ä¸‰ç»´è¡¨å¤„ç†")
    print("\n2. CSVæ–‡ä»¶ä¼šè‡ªåŠ¨ä½¿ç”¨é€šç”¨CSVæ¨¡æ¿å¤„ç†")
    print("3. å¦‚æœæ‚¨æœ‰ç‰¹å®šå…¬å¸çš„CSVæ–‡ä»¶ï¼Œè¯·åœ¨æ–‡ä»¶åä¸­åŒ…å«å…¬å¸åç§°")
    print("4. æ‚¨å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ config/csv_universal_map.jsonc é…ç½®æ–‡ä»¶")
