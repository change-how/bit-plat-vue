#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æ¦‚è§ˆæµ‹è¯•å·¥å…·
ç”¨äºå¿«é€ŸæŸ¥çœ‹ä¸Šä¼ æ–‡ä»¶çš„æ•°æ®ç»“æ„å’Œå†…å®¹æ¦‚è§ˆ
"""

import pandas as pd
import json
from pathlib import Path
import sys
import os

# è®¾ç½®å·¥ä½œç›®å½•
scripts_dir = Path(__file__).parent / 'scripts'
os.chdir(scripts_dir)
sys.path.append('.')

from data_extract import extract_data_from_sources

def show_data_overview(file_path: str, config_file: str = None):
    """
    æ˜¾ç¤ºæ–‡ä»¶çš„æ•°æ®æ¦‚è§ˆ
    
    Args:
        file_path: è¦åˆ†æçš„æ–‡ä»¶è·¯å¾„
        config_file: å¯é€‰çš„é…ç½®æ–‡ä»¶è·¯å¾„
    """
    print("="*80)
    print(f"ğŸ“‚ æ•°æ®æ–‡ä»¶æ¦‚è§ˆå·¥å…·")
    print("="*80)
    
    file_path = Path(file_path)
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    print(f"ğŸ“„ åˆ†ææ–‡ä»¶: {file_path.name}")
    print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {file_path}")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_path.stat().st_size / 1024:.2f} KB")
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    if config_file is None:
        print(f"ğŸ”§ ä½¿ç”¨é»˜è®¤é…ç½®è¿›è¡Œæ•°æ®æ¢ç´¢...")
        
        # ä¸ºä¸åŒæ–‡ä»¶ç±»å‹åˆ›å»ºé»˜è®¤é…ç½®
        if file_path.suffix.lower() == '.csv':
            # CSVé»˜è®¤é…ç½®ï¼šå°è¯•å¤šç§è¯†åˆ«æ–¹å¼
            default_configs = [
                {
                    "source_id": "standard_table",
                    "data_layout": "tabular",
                    "header_row": 1
                },
                {
                    "source_id": "search_by_header",
                    "data_layout": "find_subtable_by_header",
                    "section_header_aliases": [
                        "address", "time", "ip", "user", "wallet", "create", "login",
                        "åœ°å€", "æ—¶é—´", "ç”¨æˆ·", "é’±åŒ…", "åˆ›å»º", "ç™»å½•"
                    ],
                    "header_offset": 0
                }
            ]
        else:
            # Excelé»˜è®¤é…ç½®
            default_configs = [
                {
                    "source_id": "sheet1_data",
                    "worksheet_name": "Sheet1", 
                    "data_layout": "tabular",
                    "header_row": 1
                }
            ]
        
        configs_to_test = default_configs
    else:
        # è¯»å–æŒ‡å®šçš„é…ç½®æ–‡ä»¶
        print(f"ğŸ”§ è¯»å–é…ç½®æ–‡ä»¶: {config_file}")
        config_path = Path(config_file)
        if not config_path.exists():
            print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return
        
        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()
            # ç§»é™¤JSONæ³¨é‡Š
            lines = content.split('\n')
            clean_lines = []
            for line in lines:
                if '//' in line:
                    line = line[:line.index('//')]
                clean_lines.append(line)
            clean_content = '\n'.join(clean_lines)
            config = json.loads(clean_content)
        
        configs_to_test = config.get('sources', [])
    
    print("\n" + "="*80)
    print("ğŸ” å¼€å§‹æ•°æ®åˆ†æ...")
    print("="*80)
    
    # æ‰§è¡Œæ•°æ®æå–
    extracted_data = extract_data_from_sources(file_path, configs_to_test)
    
    if extracted_data:
        print("\n" + "="*80)
        print("ğŸ“Š æ•°æ®æ¦‚è§ˆæ€»ç»“")
        print("="*80)
        
        total_sources = len(extracted_data)
        total_records = 0
        
        for source_id, data in extracted_data.items():
            if isinstance(data, pd.DataFrame):
                total_records += len(data)
        
        print(f"ğŸ“ˆ æ€»è®¡: {total_sources} ä¸ªæ•°æ®æºï¼Œ{total_records} æ¡è®°å½•")
        
        # ç®€åŒ–æ¦‚è§ˆ
        for i, (source_id, data) in enumerate(extracted_data.items(), 1):
            print(f"\n--- æ•°æ®æº {i}: {source_id} ---")
            if isinstance(data, pd.DataFrame):
                print(f"   ç±»å‹: è¡¨æ ¼æ•°æ®")
                print(f"   å¤§å°: {data.shape[0]} è¡Œ Ã— {data.shape[1]} åˆ—") 
                print(f"   å­—æ®µ: {', '.join(data.columns)}")
            elif isinstance(data, dict):
                print(f"   ç±»å‹: é”®å€¼å¯¹æ•°æ®")
                print(f"   å¤§å°: {len(data)} ä¸ªå­—æ®µ")
                print(f"   é”®å: {', '.join(list(data.keys())[:10])}...")
            else:
                print(f"   ç±»å‹: {type(data)}")
    else:
        print("âŒ æ•°æ®æå–å¤±è´¥")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®æ–‡ä»¶æ¦‚è§ˆå·¥å…·')
    parser.add_argument('file_path', help='è¦åˆ†æçš„æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    show_data_overview(args.file_path, args.config)
