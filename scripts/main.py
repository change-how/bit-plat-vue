# main.py - è™šæ‹Ÿå¸å¹³å°æ•°æ®å¤„ç†å¼•æ“
from pathlib import Path
import pandas as pd
import commentjson
from sqlalchemy import create_engine 
from .utils import test_database_connection, load_mapping_config, get_db_engine, write_df_to_db
from .utils import determine_company_from_filename, delete_data_by_filename
from .data_extract import extract_data_from_sources, process_single_destination
from . import transforms
from .error_handler import ETLError, ErrorType, create_user_friendly_error, handle_exception, format_error_for_frontend

# --- æ•°æ®åº“é…ç½® ---
DB_CONFIG = {
    'type': 'mysql',        
    'user': 'root',         
    'password': '123456',     
    'host': '127.0.0.1',   
    'port': '3306',        
    'db_name': 'test_db'   
}

# --- æ•°æ®è½¬æ¢å‡½æ•°æ³¨å†Œè¡¨ ---
FUNCTION_REGISTRY = {
    'parse_universal_datetime': transforms.parse_universal_datetime,
    'string_to_decimal': transforms.string_to_decimal,
    'map_buy_sell': transforms.map_buy_sell,
    'extract_base_asset': transforms.extract_base_asset,
    'extract_quote_asset': transforms.extract_quote_asset,
    'map_imtoken_direction': transforms.map_imtoken_direction
}

# --- æ¨¡æ¿æ–‡ä»¶æ³¨å†Œè¡¨ï¼ˆæ”¯æŒå¤šæ¨¡æ¿ï¼‰ ---
TEMPLATE_REGISTRY = {
    'okx': [
        Path("./config/okx_map.jsonc"),
        Path("./config/okx_map_lite.jsonc")
    ],
    'binance': [
        Path("./config/binance_map.jsonc")
    ],
    'huobi': [
        Path("./config/huobi_map.jsonc")
    ],
    'imtoken': [
        Path("./config/imtoken_map.jsonc"),
        Path("./config/imtoken_map_v2.jsonc")
    ],
    'tokenpocket': [
        Path("./config/tokenpocket_map.jsonc")
    ],
    'csv': [
        Path("./config/csv_universal_map.jsonc")
    ]
}

# --- æ ¸å¿ƒæ•°æ®è¡¨åˆ—è¡¨ ---
CORE_TABLES = [
    'users',
    'transactions',
    'asset_movements',
    'login_logs',
    'devices'
]

def validate_platform_match(extracted_data: dict, platform: str, file_path: Path) -> dict:
    """
    éªŒè¯æå–çš„æ•°æ®æ˜¯å¦ä¸é€‰æ‹©çš„å¹³å°åŒ¹é…
    
    Args:
        extracted_data: æå–åˆ°çš„æ•°æ®å­—å…¸
        platform: è¯†åˆ«çš„å¹³å°åç§°
        file_path: æ–‡ä»¶è·¯å¾„
    
    Returns:
        dict: åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸ {'is_match': bool, 'reason': str, 'suggestions': list}
    """
    # æ£€æŸ¥æ˜¯å¦æœ‰æ ¸å¿ƒå¿…éœ€æ•°æ®æºè¢«æˆåŠŸæå–
    platform_signatures = {
        'binance': ['user_basic_info_raw', 'spot_trade_raw', 'deposit_raw', 'withdrawal_raw'],
        'okx': ['user_basic_info_raw', 'spot_trade_raw', 'funding_raw'],
        'huobi': ['user_basic_info_raw', 'spot_trade_raw', 'deposit_raw'],
        'imtoken': ['transaction_raw'],
        'tokenpocket': ['transaction_raw']
    }
    
    required_sources = platform_signatures.get(platform, [])
    found_sources = [key for key in required_sources if key in extracted_data and not (
        isinstance(extracted_data[key], pd.DataFrame) and extracted_data[key].empty
    )]
    
    # å¦‚æœæ‰¾åˆ°çš„æ ¸å¿ƒæ•°æ®æºå¤ªå°‘ï¼Œå¯èƒ½æ˜¯å¹³å°ä¸åŒ¹é…
    match_ratio = len(found_sources) / len(required_sources) if required_sources else 0
    
    if match_ratio < 0.5:  # å°‘äº50%çš„æ ¸å¿ƒæ•°æ®æºåŒ¹é…
        return {
            'is_match': False,
            'reason': f"æ–‡ä»¶å†…å®¹ä¸{platform}å¹³å°æ¨¡æ¿åŒ¹é…åº¦è¿‡ä½ ({match_ratio:.1%})",
            'suggestions': [
                f"å½“å‰æ¨¡æ¿æœŸæœ›æ‰¾åˆ°: {', '.join(required_sources)}",
                f"å®é™…æ‰¾åˆ°: {', '.join(found_sources) if found_sources else 'æ— '}",
                "è¯·æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†æ­£ç¡®çš„å¹³å°",
                "æˆ–ç¡®è®¤æ–‡ä»¶æ˜¯å¦ä¸ºè¯¥å¹³å°çš„æ ‡å‡†å¯¼å‡ºæ ¼å¼"
            ]
        }
    
    return {
        'is_match': True,
        'reason': f"åŒ¹é…åº¦: {match_ratio:.1%}",
        'suggestions': []
    }

def run_etl_process_for_file(file_path: Path, selected_company: str = None):
    """
    æ‰§è¡Œå•ä¸ªæ–‡ä»¶çš„å®Œæ•´ETLæµç¨‹ï¼Œå¸¦æœ‰è¯¦ç»†çš„é”™è¯¯å¤„ç†
    
    Args:
        file_path: å¾…å¤„ç†æ–‡ä»¶çš„è·¯å¾„
        selected_company: ç”¨æˆ·åœ¨å‰ç«¯é€‰æ‹©çš„å…¬å¸åç§°ï¼ˆå¦‚ï¼š'å¸å®‰', 'ç«å¸'ç­‰ï¼‰ï¼Œç”¨äºéªŒè¯åŒ¹é…
    
    Returns:
        tuple: (æ˜¯å¦æˆåŠŸ, æˆåŠŸæ¶ˆæ¯/ETLErrorå¯¹è±¡)
    """
    try:
        print("\n" + "="*80)
        print("ğŸš€ ETLæµç¨‹å¼€å§‹ - æ–°æ–‡ä»¶å¤„ç†")
        print("="*80)
        print(f"ğŸ“ å¤„ç†æ–‡ä»¶: {file_path.name}")
        print("="*80)

        # æ­¥éª¤1ï¼šæ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
        if not file_path.exists():
            raise create_user_friendly_error(
                ErrorType.FILE_NOT_FOUND,
                details=f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨"
            )

        # æ­¥éª¤2ï¼šæ–‡ä»¶æ ¼å¼æ£€æŸ¥
        supported_extensions = ['.xlsx', '.xls', '.csv']
        if file_path.suffix.lower() not in supported_extensions:
            raise create_user_friendly_error(
                ErrorType.FILE_FORMAT_ERROR,
                details=f"æ–‡ä»¶æ‰©å±•å {file_path.suffix} ä¸å—æ”¯æŒ",
                custom_suggestions=[f"æ”¯æŒçš„æ ¼å¼: {', '.join(supported_extensions)}", "è¯·è½¬æ¢æ–‡ä»¶æ ¼å¼åé‡è¯•"]
            )

        # æ­¥éª¤3ï¼šç¡®å®šæ•°æ®å¹³å°
        print("ğŸ” æ­£åœ¨è¯†åˆ«æ•°æ®å¹³å°...")
        
        # é¦–å…ˆæ£€æŸ¥ç”¨æˆ·æ˜¯å¦é€‰æ‹©äº†å…¬å¸
        if selected_company:
            print(f"ï¿½ ç”¨æˆ·é€‰æ‹©çš„å¹³å°: {selected_company}")
            # å°†å‰ç«¯é€‰æ‹©æ˜ å°„åˆ°å†…éƒ¨æ ‡è¯†ç¬¦
            company_mapping = {
                'æ¬§æ„': 'okx',
                'å¸å®‰': 'binance', 
                'ç«å¸': 'huobi',
                'ImToken': 'imtoken',
                'TokenPocket': 'tokenpocket'
            }
            user_selected_platform = company_mapping.get(selected_company)
            
            if user_selected_platform and user_selected_platform in TEMPLATE_REGISTRY:
                # éªŒè¯ç”¨æˆ·é€‰æ‹©çš„å¹³å°ä¸æ–‡ä»¶å†…å®¹æ˜¯å¦åŒ¹é…
                print(f"ğŸ”§ å°è¯•ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„å¹³å°: {user_selected_platform}")
                
                # å…ˆæ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«ä¸åŒå¹³å°çš„æ ‡è¯†
                filename_lower = file_path.name.lower()
                conflicting_platforms = []
                for platform_key in TEMPLATE_REGISTRY.keys():
                    if platform_key != user_selected_platform and platform_key != 'csv' and platform_key in filename_lower:
                        conflicting_platforms.append(platform_key)
                
                if conflicting_platforms:
                    # æ–‡ä»¶ååŒ…å«å…¶ä»–å¹³å°æ ‡è¯†ï¼Œæç¤ºç”¨æˆ·å¯èƒ½é€‰æ‹©é”™è¯¯
                    detected_platform = conflicting_platforms[0]
                    raise create_user_friendly_error(
                        ErrorType.TEMPLATE_MISMATCH,
                        details=f"æ‚¨é€‰æ‹©äº†'{selected_company}'ï¼Œä½†æ–‡ä»¶ååŒ…å«'{detected_platform}'å¹³å°æ ‡è¯†",
                        custom_suggestions=[
                            f"è¯·æ£€æŸ¥æ˜¯å¦åº”è¯¥é€‰æ‹©å¯¹åº”'{detected_platform}'çš„å¹³å°",
                            "æˆ–ç¡®è®¤æ–‡ä»¶ç¡®å®æ˜¯" + selected_company + "å¹³å°çš„æ•°æ®",
                            "æ–‡ä»¶åå’Œå¹³å°é€‰æ‹©åº”è¯¥ä¿æŒä¸€è‡´"
                        ]
                    )
                
                company_name = user_selected_platform
                print(f"âœ… ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„å¹³å°: {company_name}")
            else:
                raise create_user_friendly_error(
                    ErrorType.COMPANY_NOT_RECOGNIZED,
                    details=f"ä¸æ”¯æŒçš„å¹³å°é€‰æ‹©: {selected_company}",
                    custom_suggestions=[
                        "æ”¯æŒçš„å¹³å°: æ¬§æ„ã€å¸å®‰ã€ç«å¸ã€ImTokenã€TokenPocket",
                        "è¯·é€‰æ‹©æ­£ç¡®çš„å¹³å°"
                    ]
                )
        else:
            # ç”¨æˆ·æ²¡æœ‰é€‰æ‹©å…¬å¸ï¼Œå›é€€åˆ°æ–‡ä»¶åè¯†åˆ«
            print("ğŸ“‹ ç”¨æˆ·æœªé€‰æ‹©å¹³å°ï¼Œå°è¯•ä»æ–‡ä»¶åè¯†åˆ«...")
            company_name = determine_company_from_filename(file_path, TEMPLATE_REGISTRY)
            
            if not company_name:
                raise create_user_friendly_error(
                    ErrorType.COMPANY_NOT_RECOGNIZED,
                    details=f"æ— æ³•ä»æ–‡ä»¶å '{file_path.name}' è¯†åˆ«æ•°æ®å¹³å°",
                    custom_suggestions=[
                        "è¯·åœ¨æ–‡ä»¶åä¸­åŒ…å«å¹³å°æ ‡è¯†ï¼Œå¦‚: okx_data.xlsx, binance_äº¤æ˜“è®°å½•.csv",
                        "æ”¯æŒçš„å¹³å°å…³é”®è¯: okx, binance, huobi, imtoken, tokenpocket",
                        "æˆ–ç›´æ¥ä½¿ç”¨ .csv æ ¼å¼è®©ç³»ç»Ÿè‡ªåŠ¨å¤„ç†"
                    ]
                )
            else:
                print(f"âœ… ä»æ–‡ä»¶åè¯†åˆ«åˆ°æ•°æ®å¹³å°: {company_name}")
            
        # æ­¥éª¤4ï¼šå¤šæ¨¡æ¿æ‰«æå’ŒåŒ¹é…
        print("ğŸ“‹ æ­£åœ¨æ‰«ææ•°æ®æ¨¡æ¿...")
        template_paths = TEMPLATE_REGISTRY[company_name]
        
        if not template_paths:
            raise create_user_friendly_error(
                ErrorType.TEMPLATE_NOT_FOUND,
                details=f"å¹³å° '{company_name}' æ²¡æœ‰é…ç½®æ¨¡æ¿æ–‡ä»¶",
                custom_suggestions=["è”ç³»ç®¡ç†å‘˜æ·»åŠ æ¨¡æ¿é…ç½®", "æ£€æŸ¥ç³»ç»Ÿé…ç½®æ–‡ä»¶å®Œæ•´æ€§"]
            )
        
        # å°è¯•æ¯ä¸ªæ¨¡æ¿ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„
        successful_template = None
        successful_config = None
        successful_data = None
        template_errors = []
        
        print(f"    ğŸ” æ‰¾åˆ° {len(template_paths)} ä¸ª {company_name} æ¨¡æ¿ï¼Œå¼€å§‹é€ä¸ªå°è¯•...")
        
        for i, template_path in enumerate(template_paths, 1):
            print(f"    ğŸ“‹ å°è¯•æ¨¡æ¿ {i}/{len(template_paths)}: {template_path.name}")
            
            if not template_path.exists():
                error_msg = f"æ¨¡æ¿æ–‡ä»¶ {template_path} ä¸å­˜åœ¨"
                template_errors.append(error_msg)
                print(f"        âŒ {error_msg}")
                continue
            
            try:
                # åŠ è½½æ¨¡æ¿é…ç½®
                mapping_config = load_mapping_config(template_path)
                if not mapping_config:
                    error_msg = f"æ¨¡æ¿æ–‡ä»¶ {template_path.name} å†…å®¹ä¸ºç©º"
                    template_errors.append(error_msg)
                    print(f"        âŒ {error_msg}")
                    continue
                
                print(f"        âœ… æ¨¡æ¿é…ç½®åŠ è½½æˆåŠŸ")
                
                # å°è¯•ä½¿ç”¨è¿™ä¸ªæ¨¡æ¿æå–æ•°æ®
                print(f"        ğŸ” æµ‹è¯•æ¨¡æ¿åŒ¹é…åº¦...")
                extracted_data = extract_data_from_sources(
                    file_path,
                    mapping_config.get('sources', [])
                )
                
                # éªŒè¯å¹³å°åŒ¹é…åº¦
                if selected_company:
                    validation_result = validate_platform_match(extracted_data, company_name, file_path)
                    if not validation_result['is_match']:
                        error_msg = f"æ¨¡æ¿ {template_path.name}: {validation_result['reason']}"
                        template_errors.append(error_msg)
                        print(f"        âŒ {error_msg}")
                        continue
                
                # å¦‚æœåˆ°è¿™é‡Œï¼Œè¯´æ˜æ¨¡æ¿åŒ¹é…æˆåŠŸ
                successful_template = template_path
                successful_config = mapping_config
                successful_data = extracted_data
                print(f"        ğŸ¯ æ¨¡æ¿ {template_path.name} åŒ¹é…æˆåŠŸï¼")
                break
                
            except ETLError as e:
                # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                error_msg = f"æ¨¡æ¿ {template_path.name}: {e.message}"
                if e.details:
                    error_msg += f" ({e.details})"
                template_errors.append(error_msg)
                print(f"        âŒ {error_msg}")
                continue
            except Exception as e:
                error_msg = f"æ¨¡æ¿ {template_path.name}: å¤„ç†å¼‚å¸¸ - {str(e)}"
                template_errors.append(error_msg)
                print(f"        âŒ {error_msg}")
                continue
        
        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°äº†åŒ¹é…çš„æ¨¡æ¿
        if not successful_template:
            # æ‰€æœ‰æ¨¡æ¿éƒ½å¤±è´¥äº†ï¼Œç”Ÿæˆç»“æ„åŒ–é”™è¯¯æŠ¥å‘Š
            print(f"    âŒ æ‰€æœ‰ {len(template_paths)} ä¸ªæ¨¡æ¿éƒ½ä¸åŒ¹é…")
            
            # ç”Ÿæˆç®€æ´çš„ä¸»è¦é”™è¯¯ä¿¡æ¯
            main_error = f"å°è¯•äº† {len(template_paths)} ä¸ª {company_name.upper()} å¹³å°æ¨¡æ¿ï¼Œå‡æ— æ³•åŒ¹é…æ‚¨çš„æ–‡ä»¶"
            
            # æ„å»ºç»“æ„åŒ–çš„é”™è¯¯è¯¦æƒ…ï¼ˆä¸ºå‰ç«¯ä¼˜åŒ–æ ¼å¼ï¼‰
            structured_details = {
                "summary": main_error,
                "template_count": len(template_paths),
                "platform": company_name.upper(),
                "template_errors": []
            }
            
            # å¤„ç†æ¯ä¸ªæ¨¡æ¿çš„é”™è¯¯ä¿¡æ¯
            for i, (template_path, error) in enumerate(zip(template_paths, template_errors), 1):
                template_name = template_path.name.replace('.jsonc', '').replace('_map', '').replace(f'{company_name}_', '')
                
                # å°è¯•ä»æ¨¡æ¿æ–‡ä»¶ä¸­è¯»å–è‡ªå®šä¹‰æ˜¾ç¤ºåç§°
                display_name = None
                try:
                    if template_path.exists():
                        mapping_config = load_mapping_config(template_path)
                        if mapping_config and 'metadata' in mapping_config:
                            metadata = mapping_config['metadata']
                            # ä¼˜å…ˆä½¿ç”¨ display_nameï¼Œç„¶åæ˜¯ descriptionï¼Œæœ€åæ˜¯ version
                            display_name = metadata.get('display_name') or metadata.get('description')
                            if display_name:
                                # å¦‚æœæœ‰ç‰ˆæœ¬ä¿¡æ¯ï¼Œæ·»åŠ åˆ°æ˜¾ç¤ºåç§°ä¸­
                                version = metadata.get('version')
                                if version:
                                    display_name = f"{display_name} (v{version})"
                except Exception:
                    # å¦‚æœè¯»å–æ¨¡æ¿å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é€»è¾‘
                    pass
                
                # å¦‚æœæ²¡æœ‰è‡ªå®šä¹‰åç§°ï¼Œä½¿ç”¨æ–‡ä»¶åæ¨æ–­
                if not display_name:
                    if template_name.endswith('_lite'):
                        display_name = f"{company_name.upper()} ç®€åŒ–ç‰ˆ"
                    elif template_name.endswith('_v2'):
                        display_name = f"{company_name.upper()} V2ç‰ˆ"
                    elif template_name.endswith('_full'):
                        display_name = f"{company_name.upper()} å®Œæ•´ç‰ˆ"
                    else:
                        display_name = f"{company_name.upper()} æ ‡å‡†ç‰ˆ"
                
                # æå–é”™è¯¯çš„æ ¸å¿ƒä¿¡æ¯
                if "ç¼ºå°‘" in error and "å·¥ä½œè¡¨" in error:
                    # å·¥ä½œè¡¨ç¼ºå¤±é”™è¯¯ - æå–æ•°å­—å’Œå·¥ä½œè¡¨åç§°
                    import re
                    match = re.search(r'ç¼ºå°‘(\d+)ä¸ªå·¥ä½œè¡¨[:ï¼š]?(.*)?\(', error)
                    if match:
                        count = match.group(1)
                        sheets_part = match.group(2) if match.group(2) else ""
                        if sheets_part and "ã€" in sheets_part:
                            # æå–å…·ä½“çš„å·¥ä½œè¡¨åç§°
                            sheet_names = re.findall(r'ã€([^ã€‘]+)ã€‘', sheets_part)
                            if sheet_names:
                                # æ˜¾ç¤ºæ‰€æœ‰å·¥ä½œè¡¨åç§°ï¼Œä¸åšæˆªæ–­
                                sheets_text = "ã€".join(sheet_names)
                                error_summary = f"ç¼ºå°‘å·¥ä½œè¡¨ï¼š{sheets_text}"
                            else:
                                error_summary = f"ç¼ºå°‘ {count} ä¸ªå¿…éœ€å·¥ä½œè¡¨"
                        else:
                            error_summary = f"ç¼ºå°‘ {count} ä¸ªå¿…éœ€å·¥ä½œè¡¨"
                    else:
                        error_summary = "å·¥ä½œè¡¨ç»“æ„ä¸åŒ¹é…"
                else:
                    # å…¶ä»–ç±»å‹é”™è¯¯
                    if ":" in error:
                        error_summary = error.split(":", 1)[1].strip()
                    else:
                        error_summary = "æ¨¡æ¿æ ¼å¼ä¸åŒ¹é…"
                
                structured_details["template_errors"].append({
                    "template_name": display_name,
                    "error_summary": error_summary,
                    "original_file": template_path.name
                })
            
            # ç”Ÿæˆç®€åŒ–çš„å»ºè®®
            suggestions = [
                "ğŸ” æ¨¡æ¿åŒ¹é…ç»“æœï¼š",
                f"å·²å°è¯• {company_name.upper()} å¹³å°çš„æ‰€æœ‰ {len(template_paths)} ä¸ªæ¨¡æ¿ç‰ˆæœ¬",
                "",
                "ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š",
                "â€¢ ç¡®è®¤é€‰æ‹©çš„äº¤æ˜“å¹³å°æ˜¯å¦æ­£ç¡®",
                "â€¢ æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä¸ºå®˜æ–¹æ ‡å‡†å¯¼å‡ºæ ¼å¼", 
                "â€¢ ç¡®ä¿æ–‡ä»¶åŒ…å«æ‰€æœ‰å¿…éœ€çš„å·¥ä½œè¡¨",
                "â€¢ é‡æ–°ä»äº¤æ˜“å¹³å°å¯¼å‡ºå®Œæ•´æ•°æ®"
            ]
            
            # å°†ç»“æ„åŒ–ä¿¡æ¯è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆä¾›detailså­—æ®µä½¿ç”¨ï¼‰
            import json
            details_json = json.dumps(structured_details, ensure_ascii=False, indent=2)
            
            raise create_user_friendly_error(
                ErrorType.TEMPLATE_MISMATCH,
                details=details_json,
                custom_suggestions=suggestions
            )
        
        # ä½¿ç”¨æˆåŠŸåŒ¹é…çš„æ¨¡æ¿ç»§ç»­å¤„ç†
        mapping_config = successful_config
        extracted_data = successful_data
        print(f"âœ… ä½¿ç”¨æ¨¡æ¿: {successful_template.name}")
        print(f"âœ… æˆåŠŸåŠ è½½ {company_name} å¹³å°çš„æ•°æ®æ¨¡æ¿")
            
        print("\n" + "-"*60)
        print("ğŸ”— æ­¥éª¤1: æ•°æ®åº“è¿æ¥æµ‹è¯•")
        print("-"*60)
        # æ­¥éª¤5ï¼šæµ‹è¯•æ•°æ®åº“è¿æ¥
        try:
            test_database_connection(DB_CONFIG)
        except Exception as e:
            raise create_user_friendly_error(
                ErrorType.DB_CONNECTION_ERROR,
                details=f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}",
                custom_suggestions=[
                    "æ£€æŸ¥æ•°æ®åº“æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ",
                    "ç¡®è®¤æ•°æ®åº“è¿æ¥é…ç½®æ˜¯å¦æ­£ç¡®",
                    "æ£€æŸ¥ç½‘ç»œè¿æ¥çŠ¶æ€",
                    "è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æ•°æ®åº“çŠ¶æ€"
                ]
            )

        print("\n" + "-"*60)
        print("ğŸ—‘ï¸ æ­¥éª¤2: æ¸…ç†æ—§æ•°æ®")
        print("-"*60)
        # æ­¥éª¤6ï¼šæ¸…ç†æ—§æ•°æ®
        try:
            delete_data_by_filename(DB_CONFIG, CORE_TABLES, file_path.name)
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†æ—§æ•°æ®æ—¶å‡ºç°é—®é¢˜: {str(e)}")
            print("ç»§ç»­å¤„ç†æ–°æ•°æ®...")
        
        print("\n" + "-"*60)
        print("ğŸ“Š æ­¥éª¤3: æ•°æ®éªŒè¯å®Œæˆ")
        print("-"*60)
        # æ•°æ®å·²ç»åœ¨æ¨¡æ¿åŒ¹é…è¿‡ç¨‹ä¸­æå–å’ŒéªŒè¯äº†
        print(f"âœ… æ•°æ®æå–å®Œæˆï¼Œä½¿ç”¨æ¨¡æ¿: {successful_template.name}")
        
        if not extracted_data:
            raise create_user_friendly_error(
                ErrorType.FILE_EMPTY,
                details="ä»æ–‡ä»¶ä¸­æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®",
                custom_suggestions=["æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åŒ…å«æ•°æ®", "ç¡®è®¤æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®", "æ£€æŸ¥å·¥ä½œè¡¨æ˜¯å¦ä¸ºç©º"]
            )
        else:
            total_records = sum(len(df) for df in extracted_data.values() if isinstance(df, pd.DataFrame))
            print(f"âœ… æˆåŠŸæå–æ•°æ®ï¼Œå…± {total_records} æ¡è®°å½•")
            
        print("\n" + "-"*60)
        print("ğŸ’¾ æ­¥éª¤4: æ•°æ®è½¬æ¢å’Œå†™å…¥æ•°æ®åº“")
        print("-"*60)
        # æ­¥éª¤8ï¼šå¤„ç†æ¯ä¸ªç›®æ ‡è¡¨
        processed_tables = []
        for destination in mapping_config.get('destinations', []):
            target_table_name = destination.get('target_table')
            print(f"  ğŸ“ æ­£åœ¨å¤„ç†ç›®æ ‡è¡¨: '{target_table_name}'")

            try:
                # å¤„ç†æ•°æ®å¹¶è½¬æ¢
                final_df = process_single_destination(
                    destination,
                    extracted_data,
                    FUNCTION_REGISTRY,
                    file_path.name
                )
                
                if final_df is not None and not final_df.empty:
                    # å†™å…¥æ•°æ®åº“
                    write_df_to_db(final_df, target_table_name, DB_CONFIG)
                    processed_tables.append(target_table_name)
                    print(f"  âœ… è¡¨ '{target_table_name}' å¤„ç†å®Œæˆï¼Œå†™å…¥ {len(final_df)} æ¡è®°å½•")
                else:
                    print(f"  âš ï¸ è¡¨ '{target_table_name}' æ²¡æœ‰æ•°æ®éœ€è¦å†™å…¥")
                    
            except KeyError as e:
                raise create_user_friendly_error(
                    ErrorType.COLUMN_MISSING,
                    details=f"å¤„ç†è¡¨ '{target_table_name}' æ—¶ç¼ºå°‘å¿…éœ€å­—æ®µ: {str(e)}",
                    custom_suggestions=[
                        f"æ£€æŸ¥æ–‡ä»¶ä¸­æ˜¯å¦åŒ…å«å­—æ®µ: {str(e)}",
                        "ç¡®è®¤åˆ—åæ‹¼å†™æ˜¯å¦æ­£ç¡®",
                        "æ£€æŸ¥æ•°æ®æ¨¡æ¿é…ç½®æ˜¯å¦åŒ¹é…æ–‡ä»¶æ ¼å¼"
                    ]
                )
            except Exception as e:
                error_msg = str(e).lower()
                if 'database' in error_msg or 'connection' in error_msg:
                    raise create_user_friendly_error(
                        ErrorType.DB_WRITE_ERROR,
                        details=f"å†™å…¥è¡¨ '{target_table_name}' å¤±è´¥: {str(e)}",
                        custom_suggestions=["æ£€æŸ¥æ•°æ®åº“è¿æ¥", "ç¡®è®¤æ•°æ®åº“æœ‰è¶³å¤Ÿç©ºé—´", "æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®"]
                    )
                else:
                    raise create_user_friendly_error(
                        ErrorType.DATA_TRANSFORMATION_ERROR,
                        details=f"æ•°æ®è½¬æ¢å¤±è´¥: {str(e)}",
                        custom_suggestions=["æ£€æŸ¥æ•°æ®æ ¼å¼æ˜¯å¦æ­£ç¡®", "ç¡®è®¤æ•°æ®ç±»å‹åŒ¹é…", "åˆ é™¤å¼‚å¸¸æ•°æ®è¡Œ"]
                    )
        
        print("\n" + "="*80)
        print("ğŸ‰ ETLæµç¨‹å®Œæˆï¼")
        print("="*80)
        success_msg = f"æ–‡ä»¶ '{file_path.name}' æˆåŠŸå¤„ç†ï¼Œå…±æ›´æ–° {len(processed_tables)} ä¸ªæ•°æ®è¡¨: {', '.join(processed_tables)}"
        print(success_msg)
        return True, success_msg
                
    except ETLError as e:
        # è¿”å›ETLé”™è¯¯å¯¹è±¡ï¼Œè€Œä¸æ˜¯é‡æ–°æŠ›å‡º
        print(f"\nâŒ ETLå¤„ç†é”™è¯¯: {e.message}")
        if e.details:
            print(f"è¯¦ç»†ä¿¡æ¯: {e.details}")
        return False, e
    except Exception as e:
        # æ•è·æ‰€æœ‰æœªé¢„æœŸçš„é”™è¯¯
        error_obj = create_user_friendly_error(
            ErrorType.UNKNOWN_ERROR,
            details=f"å¤„ç†æ–‡ä»¶ {file_path.name} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}",
            custom_suggestions=["è¯·è”ç³»æŠ€æœ¯æ”¯æŒ", "æä¾›å®Œæ•´çš„é”™è¯¯ä¿¡æ¯ä»¥ä¾¿æ’æŸ¥"]
        )
        print(f"\nâŒ æœªçŸ¥é”™è¯¯: {error_obj.message}")
        print(f"è¯¦ç»†ä¿¡æ¯: {error_obj.details}")
        return False, error_obj

# --- å¼€å‘æµ‹è¯•å…¥å£ ---
if __name__ == '__main__':
    print("main.py: æ­¤æ–‡ä»¶ç°åœ¨ä¸»è¦æä¾› run_etl_process_for_file() å‡½æ•°ä¾› Flask åº”ç”¨è°ƒç”¨ã€‚")
    print("å¦‚éœ€æµ‹è¯•å¤„ç†æµç¨‹ï¼Œè¯·é€šè¿‡ web ç•Œé¢ä¸Šä¼ æ–‡ä»¶æˆ–ç›´æ¥è°ƒç”¨ run_etl_process_for_file() å‡½æ•°ã€‚")
